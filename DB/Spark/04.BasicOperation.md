# Basic Operation

## Create DataFrame

``` python
data = [
    Row("Houston","Kyle","Benny"),
    Row("Houston","Benny","charles"),
    Row("Houston","Charles","Denny"),
    Row("Omaha","carol","Brian"),
    Row("Omaha","Brian","Daniel"),
    Row("Omaha","Sara","Marry")
]

df = spark.createDataFrame(data).toDF("city","src","dst")
```

``` python
# empty Dataframe
recent_schema = StructType([
    StructField("keyword_norm",StringType(), True),
    StructField("category", StringType(), True),
    StructField("sentiment", StringType(), True),
    StructField("tf", LongType(), True)]
)

recent_df = sc.parallelize([]).toDF(recent_schema)
```

## Select , SelectExpr

``` python
df.select(col("src").alias("source"))

df.selectExpr("src AS source")
```

## literal

``` python
df.select(expr("*"), lit(1).alias("One"))
```

## Sample

``` python
seed = 5
withReplacement = False # 복원/비복원 추출
fraction = 0.5 # 결과 데이터 추출 비율

df.sample(withReplacement, fraction, seed)


# 임의 분할
dataFrames = df.randomSplit([0.25, 0.75], seed)
dataFrames[0].count() < dataFrames[1].count()
```
