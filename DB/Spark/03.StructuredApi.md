# 구조적 APi

- 데이터 흐름을 정의하는 기본 추상화 개념 
- 분산 테이블 형태의 컬렉션
- 2.0 버전에서 구조적 API 출시
- RDD 기능을 대체 : 자동화된 최적화 기능, 장애 대응 능력
- 어떤 데이터에 어떤 연산을 적용해야하는지 정의하는 지연연산 실행 계획

## 종류

- Dataset
- DataFrame
- SQL Table, View

## 스키마

1. 분산 컬렉션에 저장할 데이터 타입을 정의하는 방법
2. Dataframe의 컬럼명, 데이터 타입
3. Catalyst Engine에서 스파크 데이터 타입으로 변환하여 처리

## Row

- 연산에 최적화된 인메모리 포맷
- JVM의 Garbage Collection과 객체 초기화 부하 문제 대체

---

## 실행 과정

1. 코드를 논리적 실행 계획으로 변환 (Catalyst Optimizer)
2. 논리적 실행 계획을 물리적 실행 계획으로 변환 + 추가적인 최적화 (Catalyst Optimizer)
3. 클러스터에서 물리적 실행 계획(RDD 처리)

### 논리적 실행 계획

- 추상적 트랜스포메이션 표현 + 최적화
- 드라이버, 익스큐터 정보 무시


### 물리적 실행 계획

- 논리적 실행 계획을 클러스터 환경에서 실행 방법 정의
- 비용 모델 계산 / 비교
- RDD, 트랜스포메이션으로 컴파일

---

### Data Type Example

``` python
from pyspark.sql.types import *

b = ByteType()
```
